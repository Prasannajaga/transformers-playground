{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacb073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanna/coding/transformers-playground/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "import gzip\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import IterableDataset\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "from customTransformers import DecodeTransformer \n",
    "from utils.common import save_file_text, read_file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc12f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c77612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"roneneldan/TinyStories\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a7878",
   "metadata": {},
   "source": [
    "Mid Training QA + generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc0442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_NAMES = [\n",
    "  \"Tim\",\n",
    "  \"Tom\",\n",
    "  \"Sam\",\n",
    "  \"Bob\",\n",
    "  \"Ben\",\n",
    "  \"Max\",\n",
    "  \"Jack\",\n",
    "  \"Leo\",\n",
    "  \"Alex\",\n",
    "  \"Anna\",\n",
    "  \"Amy\",\n",
    "  \"Emma\",\n",
    "  \"Lily\",\n",
    "  \"Lucy\",\n",
    "  \"Mia\",\n",
    "  \"Ella\",\n",
    "  \"Sarah\",\n",
    "  \"John\",\n",
    "  \"Mary\"\n",
    "]\n",
    "DATASET_PATH = \"../CustomDatasets/story.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7d7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_story(story: str):\n",
    "    qas = []\n",
    "\n",
    "    sentences = story.split(\".\")\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
    "    list = {}  \n",
    "\n",
    "    for s in sentences:\n",
    "        tokens = s.split()\n",
    "        if len(tokens) < 3:\n",
    "            continue \n",
    "\n",
    "        name = tokens[0]\n",
    "\n",
    "        if name not in REAL_NAMES:\n",
    "            continue\n",
    "\n",
    "        if name.istitle():\n",
    "            qas.append({\n",
    "                \"q\": f\"who is {name.lower()} ?\",\n",
    "                \"a\": s.strip() + \".\"\n",
    "            })\n",
    "\n",
    "        if \"is\" in tokens or \"was\" in tokens:\n",
    "            qas.append({\n",
    "                \"q\": f\"what is {name.lower()} doing ?\",\n",
    "                \"a\": s.strip() + \".\"\n",
    "            })\n",
    "\n",
    "    return qas\n",
    "\n",
    "\n",
    "def convert_tinystories(dataset, max_samples=50_000):\n",
    "    output = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        story = ex[\"text\"].strip()\n",
    "        qa = generate_qa_from_story(story)\n",
    "\n",
    "        if len(qa) == 0:\n",
    "            continue\n",
    "\n",
    "        output.append({\n",
    "            \"story\": story,\n",
    "            \"qa\": qa\n",
    "        })\n",
    "\n",
    "        if len(output) >= max_samples:\n",
    "            break\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67215d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storyqa = convert_tinystories(ds, max_samples=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2bd6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packing\n"
     ]
    }
   ],
   "source": [
    "# assert not os.path.exists(DATASET_PATH) , \"Not\"\n",
    "if not os.path.exists(DATASET_PATH): \n",
    "    print(\"Packing\")\n",
    "    save_file_text(storyqa, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48a0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "storyqa_data = read_file_text(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c04d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(storyqa_data) , storyqa_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c073e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def normalize(text):\n",
    "    return \" \".join(text.strip().lower().split())\n",
    "\n",
    "def build_sft(): \n",
    "    data = read_file_text(DATASET_PATH)\n",
    "\n",
    "    sft = []\n",
    "    seen_pairs = set()\n",
    "\n",
    "    for ex in data:\n",
    "        for qa in ex[\"qa\"]:\n",
    "            pair_key = (\n",
    "                normalize(qa[\"q\"]),\n",
    "                normalize(qa[\"a\"])\n",
    "            )\n",
    "\n",
    "            if pair_key in seen_pairs:\n",
    "                continue\n",
    "\n",
    "            seen_pairs.add(pair_key)\n",
    "            sft.append({\n",
    "                \"prompt\": qa[\"q\"].strip(),\n",
    "                \"response\": qa[\"a\"].strip()\n",
    "            })\n",
    "\n",
    "    UNKNOWN_NAMES = [\n",
    "        \"billy\", \"alex\", \"john\", \"mark\", \"peter\",\n",
    "        \"sarah\", \"lucas\", \"james\", \"emma2\", \"tom2\"\n",
    "    ]\n",
    "\n",
    "    for name in UNKNOWN_NAMES:\n",
    "        for template in [\n",
    "            f\"who is {name} ?\",\n",
    "            f\"what is {name} doing ?\",\n",
    "            f\"tell me about {name}\"\n",
    "        ]:\n",
    "            sft.append({\n",
    "                \"prompt\": template,\n",
    "                \"response\": f\"I don't know who {name.capitalize()} is.\"\n",
    "            })\n",
    "\n",
    "    random.shuffle(sft)\n",
    "    save_file_text(sft, \"sft.json\")\n",
    "    print(f\"SFT samples: {len(sft)}\")\n",
    "    return sft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a1a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT samples: 271779\n"
     ]
    }
   ],
   "source": [
    "sftdata = build_sft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f143cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 271779)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(storyqa_data) , len(sftdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sftdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
