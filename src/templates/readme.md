# my-mini-stories

> A simple transformer decoder-only model trained from scratch on the **TinyStories** dataset.

## Model Details

| Parameter | Value |
| :--- | :--- |
| **Layers** | 12 |
| **Hidden Size** | 384 |
| **Attention Heads** | 6 |
| **Attention Type** | MHA |
| **FFN Type** | ReLU |
| **Vocab Size** | 50,257 |
| **Max Sequence Length** | 256 |

## Jounery

this is my first model which I trained from scratch kind of proud of myself for this i know this isn't huge but honest work, it's going to defnitely improve from here

* **Full Logs:** here is the full joruney of the model logs  
    [View Evaluation Logs](https://github.com/Prasannajaga/transformers-playground/blob/main/src/models/tiny-stories/eval.md)

* **Analysis:** here you can find deeper about the model perfomance  
    [Read Performance Details](https://github.com/Prasannajaga/transformers-playground/blob/main/src/models/tiny-stories/readme.md)

## Repository

- **GitHub**: [Prasannajaga/transformers-playground](https://github.com/Prasannajaga/transformers-playground)
- **Config Hash**: `d8b64772ec5ee4c4`